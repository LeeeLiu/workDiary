

X [3, 32, 32]
Z [48, 4, 4]

j_b-shape:[1, 6, 16, 16]  -->  [8,8]  --> [4,4]

states bpd loss [batch-size]  一个图像对应一个值



### work
1. 生成模型对比
    - 似然：VAE（让图像编码的潜在向量服从高斯分布，从而实现图像的生成。优化了数据对数似然的下界，生成图片模糊）、自回归（并行性差，速度慢）、flow（精确推理潜在变量，精确优化对数似然。可并行。潜在变量数据点之间可插值、可进行有目的修改。但是，太耗资源）。
    - 缩小`真实数据`和`生成数据`之间的差距：**GAN**（缺点是，缺乏对潜在变量的准确表示编码，生成数据多样性差，训练不稳定）
2. 嵌入域
    - Z
    - 将Z进行熵编码之后的比特流c(×)
3. 中间表示分布是什么鬼？
    loss = 对数似然取负 = -Σ（按照后三个维度加）（z的先验分布pz + 中间表示的先验分布ps  +  z对x的雅可比行列式
4. 当生成模型是概率模型，且损失函数是对数似然的时候：
损失最小化     <-----------等价------------->   极大似然估计




### 实验
- imagenet32
    batch-size：128     train+val set：20w个  epoch：100    time：35min/epoch


### 概率论回顾
1. `极大似然估计`：假设样本x服从某种参数为θ的分布p。根据已知x，反推最大可能导致样本结果的参数θ。 这个结果，和`最小二乘（正规方程组）`计算出来的一样。
2. 为什么不用后者方法，直接算？因为数据量很大，直接算太慢。


### 白化(whitening)
1. 目的:降低输入的冗余性。
2. 白化之后，学习算法的输入具有如下性质：
(i)特征之间相关性较低；(ii)所有特征具有相同的方差。


### NICE
> [链接](https://zhuanlan.zhihu.com/p/41912710)
1. h = f(x)：f是可逆的，h的维数与x的维数相同。
2. f是学习来的。先验分布pH(h)可以是预定义，也可以学习得来。
3. 表示学习：扩展与输入中“有趣”区域相关联的表示空间的体积。
4. 评估标准：**最大化** `log-likelihood`

加性耦合层：通过交错的方式来混合信息流（等价于直接反转原来的向量）

- 由于z的每个维度的独立性，理论上我们控制改变单个维度时，就可以看出生成图像是如何随着该维度的改变而改变，从而发现该维度的含义。
- 对两幅图像的编码进行插值（加权平均），得到过渡自然的生成样本，这些在后面发展起来的Glow模型中体现得很充分。

### RealNVP
> [链接](https://zhuanlan.zhihu.com/p/43048337)
1. 评估标准：`bits per dimension`-->`average negative log-likelihood`

加性和乘性耦合层结合 “仿射耦合层”
通过随机打乱（每一步 flow 输出的两个向量 h1,h2 拼接成一个向量 h，然后将这个向量重新随机排序），信息混合更充分，最终的 loss 可以更低。
分割和打乱操作，都只对“通道”轴执行。
在耦合模型中引入了卷积层

多尺度：（factor out）
映射得到的最终潜在空间不是一次得到的，而是通过不同尺度潜在变量拼接而成的。
抛弃了 p(z) 是标准正态分布的直接假设，而采用了一个组合式的条件分布。
减少运算量，解决维度浪费问题，表示不同维度的重要性。

### Glow
[ZhiHu](https://zhuanlan.zhihu.com/p/39676312)
[openai-blog](https://openai.com/blog/glow/)
引入了`可逆1x1卷积`来代替排序层

h = xW
1. 初始化时，为了保证 W 的可逆性，使用"随机正交矩阵"初始化W。
2. W = PLU。将W进行LU分解。其中 P 是一个置换矩阵，也就是前面说的 shuffle 的等价矩阵；L 是一个下三角阵，对角线元素全为 1；U 是一个上三角阵。
3. 训练策略：固定 P，也固定 U 的对角线的正负号，然后约束 L 为对角线全 1 的下三角阵，U 为上三角阵，优化训练 L,U 的其余参数。 
4. 大家都训练到最优的情况下，可逆1×1卷积的图像生成质量才是最优的。（和简单反转、shuffle相比）但是，可逆1x1卷积达到饱和所需要的 epoch 数更多。



### Glow的优缺点
- 优点
对潜在变量插值，可以生成中间过渡类型的自然图像。（假设先验分布z的每个维度iid--> x的每个维度iid）
- 缺点：耗费资源太大
cifar10（32x32），跑了 700 个 epoch，效果：远看似乎还可以，近看啥都不是。
256x256高清人脸图像生成，需要训练 4000 个 epoch，用 40 个 GPU 训练了一周，简单理解就是用 1 个 GPU 训练一年……



### IDF
[IDF-code](https://github.com/jornpeters/integer_discrete_flows)