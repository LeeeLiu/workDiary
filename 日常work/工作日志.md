

### 待整理
mtb操作 在lt_tests.m里
py操作 见save_stego.py，dim1TOdim2.py


### 反卷积 -> 插值+卷积
[reference](https://distill.pub/2016/deconv-checkerboard/#citation)
interpolate意思是：
	deconvolution -->
	nearest neighbor interpolation `+` regular convolution




### old-experiment
>使用resnet-34，用于训练cover-stego共1200对，验证的是300对。
批次大小64，epoch=100。
- 不同负载下的val检测率：
α  	  train_acc:			valid_acc
0.05  0.6和0.7波动（发散）， 0.4267
0.1   0.96 ， 				0.5317
0.2	  0.96 ，				0.53
0.4	  0.96, 			 	0.5333
- (batch-size=16)
0.4	  0.9933, 			 	0.8533    
结论：减小批次，收敛慢，但是泛化性能好一些；
增大批次，收敛快，但是泛化性能差（即过拟合，在训练集上表现好，在验证集上表现没那么好。）


>10.23收获
torch中，cover-stego名字对应问题:规范方式建议(修改QmdctDataset的get_item内置函数)

>去年 wav 1536 --> aac 80多kbps
wav 256 kbps --> aac 30多 kbps
最大秘密信息比特率 =（128×1024×0.5）/8 == 8.192 kbps


### 批次大小的影响
1. resnet-18
	- 1.1 80样本，32批次大小。收敛效果好。（结论：增大批次有利于收敛）（lab电脑，finish）
	- 1.2 1500样本，64批次大小。（lab电脑，finish）
### resnet种类
2. resnet-34 
	- 2.1 在1.2基础上做2个改动：resnet_18->resnet_34，通道数改为4 10 20 40(否则内存不足)（`收敛了`）
	- 2.2 在以上基础上（1）加一层fix_conv（2）通道数改为10 10 20 40（没有2.1收敛得好）
	- 2.3 （再次进行2.1。epoch改为300，发现效果更好，不知为啥？）
### 把（2.1）放进GAN
1. resnet-34, 1500-sample，`64 batch-size`，200-epoch。和（2.1设置相同）
2. 生成器loss中，0.4 -> 0.25 结果不好，概率图都是黑色的。
3. u-net 加学习率衰减（finish）


3. my version(暂时弃用，后续看看有救不)
	>3.1 在1.2基础上，(1)resnet-18 --> my version ,  (2)64->16（内存不足。my version更吃内存）。
	  这个效果很差（loss和acc都是基本没变化，图就不存了）（lab电脑）
	- 3.2 测试my version有效性。在3.1基础上，改动(1)样本数目1500-->80或者(2)去掉fix_conv通道4->1 (还是不行，效果同上。)
>笔记本上的实验。说服力不足。
（1）resnet_18 ,  batch_size=8,  cover-stego 80对。（十几个epoch，还没有收敛。图片见微信）
（2）在（1）基础上做1个改动resnet_18->resnet_34 （50 epoch。没有收敛，同上。）

>10.12 下午
输入秘密信息，如果秘密信息小于嵌入容量，则补0；否则，按照嵌入容量来截取秘密信息长度，从而做嵌入。所以，最终嵌入的比特数=嵌入率×载体长度（Qmdct个数，即样本点个数）
回顾：采样率×位深度×通道数 == 码率
秘密信息比特率 == 秘密信息长度/时间

>10.9上午+晚上
概率->失真 在单个音频里面测试完毕（嵌入率为0.5），人耳听不出来。
工作目录：wav_process/pro_cost_STC
wav音频已copy至U盘。

>10.8上午
1. 单独训练torch官方实现的resnet（加了小改动）效果：
	- loss下降很快。但是50 epoch左右开始波动，之后再下降。
	- acc上升很快。大概稳定在0.973。但是但是50 epoch左右开始波动，之后再上升。
2. GAN：torch官方实现的resnet + U-net训练效果
	- 300 epoch，8 batch_size，1500样本；
	- 概率0-0.5，权重1e-10
	- valid acc：总体上看判定为stego的样本多，判为cover的少。可见生成的图像还是会被判别器认出能够被正确分类，没有达到欺骗判别器的效果。
	- train acc：没有统计。
	- 进展：和自己复现的resnet版本相比，得到的pro_image更精细一些。
	

>10.6中午
怎样组合高效的网络？大量阅读现有的成功案例。
>9.8晚上
将MP3隐写分析run成功（loss有波动现象）
问题：Dnet的loss降不下来
原因分析：可能因为每一帧末尾部分很多0系数参与了计算，cover和stego的区别不容易放大。（正在做实验验证）
>9.7晚上
回顾了一阶二阶差分、马尔可夫转移概率、联合密度的含义。
>9.7上午
1. HPF
    - 一种特殊的卷积 卷积核权重不变
	- 作用：放大隐写带来的影响
2. 1×1 卷积核作用
	- 跨通道聚合
	- 降维/升维（通道数），减少参数，避免过拟合
    ![1×1卷积核](https://img-1300025586.cos.ap-shanghai.myqcloud.com/1%C3%971%E5%8D%B7%E7%A7%AF%E6%A0%B8.png)
3. subsample 下采样

>9.4晚上
training 自动调整普通参数 梯度是变化的
validate 人工调整超参数(迭代数、学习率等) 不参与梯度下降
test 不调整参数
问题：discriminator的loss降不下来
解决方法：（1）stego_gan.py里修改loss函数。

>9.4上午
问题：training过程如果因为意外终止，此时重新开始（epoch=1）。考虑到这个问题，查阅[资料1](https://www.aiuai.cn/aifarm657.html),[资料2](https://pytorch.org/tutorials/beginner/saving_loading_models.html)。
>项目GAN-STC_QMDCT采用的是“Saving & Loading a General Checkpoint”方法。但是它是放在test过程里的，后续肯定要把它放在training里。

>9.3晚上
V(D, G) = log D(x) + log( 1-D( G_z ) )
D* = max V(D, G)
G* = min D*
（多一个负号就是交叉熵）
对于判别器D：
d_loss_on_cover = CE(d_on_cover, cover真实label 0)
d_loss_on_stego = CE(d_on_stego, stego真实label 1)
d_total_loss = d_loss_on_cover + d_loss_on_stego
交叉熵回顾：
\[H(p,q) = \sum\limits_i {p(i)\log \frac{1}{{q(i)}}} \]

所以，H(真/假label, D(x)或D(G_z) )就是计算真/假数据与目标标签的差别。
d_total_loss和 - V(D, G)含义相同。

run -> edit configurations 有输参数的地方

>9.3 上午 下载torch
不要venv 用真实环境(C盘的解释器) 下载包（连校园网）


* 制作gif动图
1. 把PPT另存为多个图片
2. 把这些图片导入screen2gif，选择合适延迟间隔，另存为gif。

* 下载：用迅雷

