


使用条件生成： latent z(256维) + pitch(61维) = latent vector(317维)。所以discriminator需要预测pitch label。
生成语谱图、相位
预测IF spectra频谱图 比phase 更能够生成coherent waveforms

### 频域表示
spectral images size (128,1024,2)
1.  “phase” model：STFT_magnitude、phase。
2. “IF”model：“instantaneous frequency”，可以根据phase计算。
3. IF-Mel：log(magnitude) + IF --> a mel frequency scale 
>使用tf内置函数，可以计算STFT的值(magnitude)、相位角(phase angle)。（看看代码。每个维度含义是？loss定义的是？magnitude是什么？）

### 效果
1. 相位-连贯
2. CONSISTENT TIMBRE ACROSS PITCH：不同基音（音高、音调），音色能够保持一致性。
固定latent conditioning，改变 pitch conditioning。
3. 比WaveNet生成的音质好，速度更快。
原因：autoregressive model结构（比如WaveNet）采样速度较慢（依赖低效的原始采样，每次生成一个音频样本），
而所有基于GAN的结构（比如生成器G中的转置卷积），来实现有效的并行采样、全局潜在控制。

### 评估音质、多样性
1. 人类评估员：样本A的音质比样本B好/差。
2. Number of Statistically-Different Bins (NDB)：评估多样性。方法和K-means有关。
3. Inception Score(IS)：衡量生成模型的个体特征和整体特征。
个体特征：生成样本能够划分到某一个类别中。即，生成的1个样本属于某一类别的概率大，其他概率小。
整体特征：生成样本要有多样性。即，生成的很多样本，尽量属于不同类别。
4. PA，PE( Pitch Accuracy, and Pitch Entropy)：正确分类pitch的能力。
5. Fr´echet Inception Distance (FID) ：评估 音质、多样性。（IS的补充）

### MIDI
MIDI文件是一种描述性的“音乐语言”，它将所要演奏的乐曲信息用字节进行描述。譬如在某一时刻，使用什么乐器，以什么音符开始，以什么音调结束，加以什么伴奏等等，MIDI文件本身并不包含波形数据，所以MIDI文件非常小巧。
MIDI要形成电脑音乐必须通过合成。它首先将各种真实乐器所能发出的所有声音（包括各个音域、声调）进行取样，存储为一个波表文件。
在播放时，根据MIDI文件记录的乐曲信息向波表发出指令，从“表格”中逐一找出对应的声音信息，经过合成、加工后回放出来。


### PG-GAN
def G_paper https://github.com/tkarras/progressive_growing_of_gans/blob/master/networks.py (官方)
### GANsynth
class Generator(nn.Module): https://github.com/ss12f32v/GANsynth-pytorch/blob/master/PGGAN.py (非官方)
def generator https://github.com/tensorflow/magenta/blob/master/magenta/models/gansynth/lib/networks.py (官方)


### image VS. audio
1. 图像的主要成分通常捕捉强度、梯度和**边缘**特征，
2. 而音频的主要成分是**周期性**函数，将音频分解为组成频带。

VAE：
encode图像X --> latentcode(z,c) --> reparameterize得到latent_sample-->
decode latent_sample --> reconstruct图像X
>Z连续变量、C离散变量（表示类别的分布）
图像：32×32
latent_dist的cont 2个8×10矩阵，disc 8×10 (用到softmax)
latent_sample    8×20


### 使用sigmoid
1. ASDL、UT-SCA、JS-GAN 最后一个layer都用了sigmoid。--> 概率
  "joint VAE"说 The non linearities in both the encoder and decoder are ReLU except for the output layer of the decoder which is a sigmoid.
  pix2pix的D的最后一层是sigmoid
2. U-net用到soft-max

[U-net：paper+code](https://github.com/milesial/Pytorch-UNet)
[VAE：paper+code](https://github.com/Schlumberger/joint-vae)

### 去卷积
1. 以下都是同义表达：
up-sampling、transpose、
(bad name)de-convolution、up convolution、
fractionally strided convolution、backward strided convolution
2. 卷积：4×4 --> 2×2
去卷积：2×2 --> 4×4。和卷积运算方式一样，使用填充、步长、转置的filter，就可以还原4×4图像。

VAE：
1. Auto-Encoding Variational Bayes：2014（future work是将CNN用到VAE中来）
2. Stochastic backpropagation and approximate inference in deep generative models

auto-encoder
1. Y. Bengio and Y. LeCun. Scaling learning algorithms towards AI. In L. Bottou, O. Chapelle, D. DeCoste, and J. Weston, editors, Large Scale Kernel Machines. MIT Press, 2007.
2. Y. Bengio, P. Lamblin, D. Popovici, and H. Larochelle. Greedy layer-wise training of deep networks. In Bernhard Sch¨olkopf, John Platt, and Thomas Hoffman, editors, Advances in Neural Information Processing Systems 19 (NIPS’06), pages 153–160. MIT Press, 2007.
3. Efﬁcient Learning of Sparse Representations with an Energy-Based Model
4. Hinton, G.E. and Zemel, R.S. (1994) Autoencoders, minimum description length, and Helmholtz free energy. （目前发现最早的）

U-net: Convolutional networks for biomedical image segmentation. InMICCAI, 2015. 2, 3 


### pytorch的交叉熵
注：有weight的时候，在下式基础上乘一个weights[class]
$\operatorname{loss}(x, class)=-\log \frac{e^{x[\text {class}]}}{\sum_{j} e^{x[j]}}=-x[\text { class }]+\log \left(\sum_{j} e^{x[j]}\right)$


### pix-pix-GAN
1. 目标：基于匹配数据的两个领域的转换
2. 基于的思路：cGAN（前人工作不用cGAN也可以做，但是那样只能针对特定的两个领域，本文旨在给出通用的解决方案）
GAN：noise z -> y ，cGAN：image x + noise z -> y。
3. 基于的网络结构：DCGAN

>Conv-BN-ReLU
1. CNN的使用动机：解决输入数据量太大的问题，节省训练开销 
2. BN(Batch Normalization归一化)：加快学习速度
（改善深层神经网络：超参数调试、正则化以及优化 第三周）
3. 激活函数ReLU

### 路线
关注：瞄准工业界需求的团队、比赛(kaggle)
自身条件：理论基础、算法与coding、深入理解C++(不是掌握语法)
长远价值的方向：底层开发->移动端部署神经网络、帮助失语者生成语音、无人驾驶

### 记录
>overfitting发生的四个常见原因
data size N、stochastic noise、deterministic noise和excessive power(使用了过于复杂的模型)

>解决方法：
regularization正则化（减少连接、权重decay降低hypothesis阶数、提前stop），
增加验证集validataion，
dropout（DL中）
dropout(解决过拟合)，cropout（从encoded image里裁剪）




### 链接
[GAN和隐写](https://zhuanlan.zhihu.com/p/51263749?utm_source=com.tencent.tim&utm_medium=social&utm_oi=975667395150483456)

[正则化与SVM](https://mp.weixin.qq.com/s?__biz=MzIwOTc2MTUyMg==&mid=2247483942&idx=1&sn=564b65607d2e682bdedfdba51296a80e&chksm=976fa7bba0182ead76a6a22cf4d720efa281287c710beeb9304fc59057356029d8c7c2fac4f3&scene=21#wechat_redirect)

[Softmax多分类，是Logistic（sigmoid）二分类的推广](https://blog.csdn.net/hellocsz/article/details/80813546)

[python中的字符数字之间的转换函数](https://www.cnblogs.com/wuxiangli/p/6046800.html)